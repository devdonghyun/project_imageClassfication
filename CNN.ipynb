{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "def CNN(_x, _w, _b):\n",
    "    # RESHAPE\n",
    "    _x_r = tf.reshape(_x, shape=[-1, 28, 28, 1])\n",
    "    # CONVOLUTION\n",
    "    _conv1 = tf.nn.conv2d(_x_r, _w['c1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # ADD BIAS\n",
    "    _conv2 = tf.nn.bias_add(_conv1, _b['c1'])\n",
    "    # RELU\n",
    "    _conv3 = tf.nn.relu(_conv2)\n",
    "    #MAX-POOl\n",
    "    _pool = tf.max_pool(_conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "    # SECOND CONV LAYER\n",
    "    _temp = tf.nn.conv2d(_pool, _w['c2'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    _temp = tf.nn.bias_add(_temp, _b['c2'])\n",
    "    _temp = tf.nn.relu(_temp)\n",
    "    _temp = tf.nn.max_pool(_temp, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # VECTORIZE\n",
    "    _dense = tf.reshape(_temp. [-1, _w['d1'].get_shape().as_list()[0]])\n",
    "    # DENSE\n",
    "    _logit = tf.add(tf.matmul(_dense, _w['d1']), _b['d1'])\n",
    "    _out = {\n",
    "        'x_r' : _x_r, 'conv1' : _conv1, 'conv2' = conv2, 'conv3' : _conv3,\n",
    "        'pool' : _pool, 'dense' : _dense, 'logit' : _logit'\n",
    "}\n",
    "return _out\n",
    "\n",
    "# PREDICTION\n",
    "cnnout = CNN(x, weights, biases)\n",
    "\n",
    "# LOSS AND OPTIMZER\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=cnnout['logit']))\n",
    "optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "corr = tf.equal(tf.argmax(cnnout['logit'], 1), tf.argmax(y, 1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "\n",
    "# INITIALIZER\n",
    "init = tf.global_variables_initializer()\n",
    "print (\"FUNCTION READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "display_step = 4\n",
    "# LAUNCH THE GRAPH\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# OPTIMIZER\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # ITERATION\n",
    "    for i in range(total_batch):\n",
    "       batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        sess.run(optm, feed_dict=feeds)\n",
    "    avg_cost = avg_cost / total_batch\n",
    "    # DISPLAY\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print (\"Epoch : %03d/%03d cost : %.9f\" % (epoch+1, training_epochs, avg_cost))\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TRAIN ACCURACY : %.3f\" % (train_acc))\n",
    "        feeds = {x: mnist.test.images[:100, :], y: mnist.test.labels[:100, :]}\n",
    "        test_acc = sess.run(accr, feed_dict=feeds)\n",
    "        pirnt (\"TEST ACCURACY: %.3f\" % (test_acc))\n",
    "    # SAVE\n",
    "    if (epoch+1) % save_step == 0:\n",
    "        savename = savedir+\"net-\"+str(epoch+1)+\".ckpt\"\n",
    "        saver.save(sess. savename)\n",
    "        print (\"[%s] SAVED\" % (savename))\n",
    "print (\"OPTIMIZATION FINISHED\")"
   ]
  }
 ]
}